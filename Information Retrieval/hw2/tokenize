#!/bin/sh

#####################################################################
#
# Usage:  tokenize filename
#
#    Input:   filename.raw        (raw text file)
#    Output:  filename.tokenized  (tokenized with one word or symbol per line)
#
#####################################################################

DIR=/home/1/yarowsky/cs466/hw2

$DIR/token1 < $1.raw | 
sed 's/[ 	]*$//' | 
egrep . > $1.tokenized

